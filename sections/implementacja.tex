
\subsection{Tworzenie obiektu odpowiadającego sieci neuronowej}

Teraz przedstawię autorską implementację przedstawionego wcześniej algorytmu.
Podstawą jest klasa odwzorowującej sieć neuronową, w moim przypadku
taką funkcję pełni klasa NeuralNetwork, która to implementuje interfejs pokazany na listingu \ref{lst:INeuralNetwork}.

\begin{lstlisting}[caption={Interfejs INeuralNetwork}, label={lst:INeuralNetwork}]
  public interface INeuralNetwork
  {
      IEnumerable<IInputNeuron> InputLayer { get; }
      IEnumerable<IHiddenNeuron> HiddenLayer { get; }
      IEnumerable<IOutputNeuron> OutputLayer { get; }
      IErrorFunction ErrorFunction { get; }
      void FillInputNeurons(IEnumerable<double> input);
      IEnumerable<double> CalculateOutput();
  }
\end{lstlisting}

W tym momencie skupmy się na linijkach 3, 4 i 5, które to wskazują na to, że sieć neuronowa zawiera warstwy wejściową, ukrytą i wyjściową.
Jak widzimy każda warstwa posiada inny typ neuronu, co wynika to z tego, że w zależności od warstwy neurony się różnią. Przykładowo:
\begin{itemize}
  \item Neuron warstwy wejściowej nie ma możliwości dodawanie połączeń wejściowych.
  \item Neuron warstwy wyjściowej nie ma możliwości dodawanie połączeń wyjściowych.
  \item Neuron warstwy ukrytej ma możliwość dodawanie obu typów połączeń.
\end{itemize}

Obiekt klasy NeuralNetwork jest tworzony z wykorzystaniem wzorca "Builder".
Dzieje się to w sposób pokazany na listingu \ref{lst:NeuralNetworkBuilder}.

\begin{lstlisting} [caption={Budowanie obiektu NeuralNetwork},label={lst:NeuralNetworkBuilder}]
  var neuralNetworkBuilder = new NeuralNetworkBuilder();
  var network = neuralNetworkBuilder
      .SetNumberOfInputNeurons(2)
      .SetNumberOfOutputNeurons(1)
      .SetActivationFunction(new SigmoidActivationFunction())
      .SetErrorFunction(new MeanSquaredErrorFunction(1))
      .SetNumberOfHiddenNeurons(2)  //opcjonalne
      //.AddBiasConnections()         //opcjonalne
      .Build();
\end{lstlisting}

Klasa NeuralNetworkBuilder umożliwia stworzenie sieci neuronowej:
\begin{itemize}
  \item Zawierającą wybraną ilość neuronów warstwy wejściowej.
  \item Zawierającą wybraną ilość neuronów warstwy wyjściowej
  \item Działającą na określonej funkcji aktywacji
  \item Wyliczającej błąd na podstawie wybranej funkcji
  \item Umożliwiającej opcjonalne dodanie warstwy ukrytej
  \item Umożliwiającej opcjonalne dodanie połączeń do biasów
\end{itemize}

Zadaniem Buildera jest stworzenie obiektu klasy NeuralNetwork, który spełni podane wymagania. 
W zależności od tego czy użytkownik będzie potrzebował warstwy ukrytej, Builder utworzy sieć która ma połączenia z warstwą pośrednią lub też bezpośrednie połączenia warstwy wejściowej z wyjściową.
Podobnie jest z wyborem tego czy czy powinny być tworzone biasy czy też nie.
Builder nie posiada żadnej metody dotyczącej wyboru pierwotnych wag połączeń, co wynika z tego, że zgodnie z założeniem algorytmu wstecznej propagacji są one inicjalizowane losowo.

Dla tak stworzonej sieci neuronowej możemy przeprowadzić obliczenia, które zostały przedstawione w poprzednim podrozdziale.
Robimy to w sposób przedstawiony w listingu \ref{lst:CalculateOutput}

\begin{lstlisting} [caption={Budowanie obiektu NeuralNetwork},label={lst:CalculateOutput}]
  network.FillInputNeurons(new double[] { 0, 1 });
  var output = network.CalculateOutput();
\end{lstlisting}

W pierwszej kolejności są wypełniane neurony wejściowe.
Jeśli użytkownik poda liczbę danych wejściowych różniącą się od liczby neuronów warstwy wejściowej zostanie wyrzucony wyjątek.

Wyjście sieci jest liczone w sposób rekurencyjny:
\begin{itemize}
  \item Wyjście każdego neuronu z wyjątkiem neuronów wejściowych jest sumą wyjść połączeń wejściowych poddaną funkcji aktywacji (listing \ref{lst:NeuronOutput}).
  \item Wyjście połączenia jest iloczynem wagi i wyjścia neuronu źródłowego (listing \ref{lst:ConnectionOutput})
\end{itemize}

\begin{lstlisting} [caption={Wyliczanie wyjścia neuronu},label={lst:NeuronOutput}]
  public class OutputNeuron : IOutputNeuron
  {
      //***
      public double NetOutput => _inputConnections.Sum(x => x.Output);
      public double Output => _activationFunction.Invoke(NetOutput);
      //***
  }
\end{lstlisting}


\begin{lstlisting} [caption={Wyliczanie wyjścia połączenia},label={lst:ConnectionOutput}]
  class NeuronConnection: INeuronConnection
  {
      //***
      public double Output => Weight * _source.Output;
      //***
  }
\end{lstlisting}

\subsection{Implementacja treningu sieci neuronowej}

Aby rozpocząć proces uczenia należy stworzyć instancję klasy Trainer, która to przyjmuje w konstruktorze
informację na temat sieci, którą będziemy chcieli uczyć oraz stałej uczenia. 
Kolejnym krokiem jest przygotowanie danych testowych, na podstawie których nauczymy naszą sieć określonych zachować.
Następnie należy wywołać funkcję Train, przekazując jej kolekcję danych testowych oraz warunki stopu,
to znaczy maksymalną liczbę epok po których nauczanie się zatrzyma oraz błąd po którego osiągnięciu zostanie zakończone.
Cała ta procedura została pokazana na listingu \ref{lst:train-invoke}.


\begin{lstlisting} [caption={Rozpoczęcie procesu uczenia },label={lst:train-invoke}]
  var trainer = new Trainer(neuralNetwork: network, learningRate: 0.01, logger: new ConsoleLogger());
  var trainDataCollection = new[]
  {
      new TrainData(new double []{ 0, 0 },new double [] { 1 } ),
      new TrainData(new double []{ 1, 0 },new double [] { 0 } ),
      new TrainData(new double []{ 0, 1 },new double [] { 0 } ),
      new TrainData(new double []{ 1, 1 },new double [] { 1 } ),
  };
  trainer.Train(trainDataCollection, numberOfEpochs: 1000000, terminalEpochError:0.01);
\end{lstlisting}

Sama funkcja Train steruje przebiegiem uczenia (listing \ref{lst:train-invoke})
W pierwszej kolejności wywołuje funkcję odpowiedzialną za sprawdzenie tego czy w danych testowych liczba danych na wejściu oraz na wyjściu zgadza się z liczbą neuronów w odpowiednich warstwach.
Jeśli ten warunek jest spełniony funkcja wywołuje w pętli metodę TrainForSingleEpoch do czasu aż zostanie spełniony którykolwiek warunek stopu.

\begin{lstlisting} [caption={Funkcja Train},label={lst:train-function}]
  public void Train(TrainData[] trainDataCollection, int numberOfEpochs, double terminalEpochError)
  {
      ValidateTrainData(trainDataCollection);

      for (int i = 0; i < numberOfEpochs; ++i)
      {
          var epochError = TrainForSingleEpoch(trainDataCollection);
          _logger.Info($"Epoch {i+1}, error: {epochError}");
          if (epochError <= terminalEpochError)
          {
              break;
          }
      }
  }
\end{lstlisting}

Funkcja TrainForSingleEpoch (listing \ref{lst:TrainForSingleEpoch-function}) iteruje po danych testowych wewnątrz jednej epoki wywołując na nich szereg funkcji.
Pierwszą z nich jest ta wypełniająca sieć danymi testowymi na wejściu (linia 6)
Dzięki tej operacji funkcja HandleOutputLayer jest w stanie obliczyć błąd średniokwadratowy między wartością oczekiwaną a rzeczywistą, a także współczynnik delta.
Współczynnik ten będzie przydatny przy liczeniu nowych wag zgodnie z opisem z poprzedniego rozdziału.

W przypadku funkcji HandleHiddenLayer liczenie współczynnika delty dla danych neuronów warstwy ukrytej jest jedynym zadaniem funkcji.


\begin{lstlisting} [caption={Funkcja TrainForSingleEpoch},label={lst:TrainForSingleEpoch-function}]
  private double TrainForSingleEpoch(TrainData[] trainDataCollection)
  {
      double totalEpochError = 0;
      foreach (var trainData in trainDataCollection)
      {
          _network.FillInputNeurons(trainData.Inputs);
          HandleOutputLayer(trainData.ExpectedOutputs);
          HandleHiddenLayer();
          UpdateWeights();
          totalEpochError += _network.OutputLayer.Sum(x => x.Error);
      }
      return totalEpochError;
  }

  private void HandleOutputLayer(double[] expectedOutputs)
  {
      for (int i = 0; i < expectedOutputs.Length; ++i)
      {
          var outputNeuron = _network.OutputLayer.ElementAt(i);
          var expectedOutput = expectedOutputs[i];

          outputNeuron.CalculateError(_network.ErrorFunction, expectedOutput);
          outputNeuron.CalculateDeltaError(_network.ErrorFunction, expectedOutput);
      }
  }
  private void HandleHiddenLayer()
  {
      foreach (var hiddenNeuron in _network.HiddenLayer)
      {
          hiddenNeuron.CalculateDeltaError();
      }
  }

\end{lstlisting}

Funkcja UpdateWeights iteruje po wszystkich połączeniach w zależności od tego czy są biasy czy zwykłe połączenia między neuronami wywołuje na nich odpowiednie funkcje.
Najpierw przyjrzyjmy się funkcji UpdateNeuronConnectionWeight, która jest wykorzystywana do aktualizowania wag zwykłych neuronów.


\begin{lstlisting} [caption={Funkcja UpdateNeuronConnectionWeight},label={lst:UpdateNeuronConnectionWeight-function}]
  private void UpdateWeights()
  {
      var connectionsInNetwork = _network.OutputLayer.SelectMany(x => x.InputConnections).Concat(_network.HiddenLayer.SelectMany(x => x.InputConnections));
      foreach (var connection in connectionsInNetwork)
      {
          if (connection is INeuronConnection neuronConnection)
          {
              UpdateNeuronConnectionWeight(neuronConnection);
          }
          else if (connection is IBiasConnection biasConnection)
          {
              UpdateBiasConnectionWeight(biasConnection);
          }
      }
  }
  private void UpdateBiasConnectionWeight(IBiasConnection biasConnection)
  {
      var derivatateOfTotalErrorToWeight = biasConnection.Destinations.Select(x => x as INeuronWithDeltaError).Sum(x => x.DeltaError);
      biasConnection.Weight -= _learningRate * derivatateOfTotalErrorToWeight;
  }
  private void UpdateNeuronConnectionWeight(INeuronConnection neuronConnection)
  {
      var destinationNeuron = neuronConnection.Destination as INeuronWithDeltaError;
      var derivatateOfTotalErrorToWeight = neuronConnection.Input * destinationNeuron.DeltaError;
      neuronConnection.Weight -= _learningRate * derivatateOfTotalErrorToWeight;
  }
\end{lstlisting}